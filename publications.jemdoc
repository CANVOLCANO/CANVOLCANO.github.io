# jemdoc: menu{MENU}{publications.html}, nosource
== Publications and Preprints
\n
(* indicates equal contribution)

=== Publications
==== 2023
- Best-of-three-worlds analysis for linear bandits with follow-the-regularized-leader algorithm \n
Fang Kong, *Canzhe Zhao*, and Shuai Li, \n
COLT, 2023.
- DPMAC: Differentially private communication for cooperative multi-agent reinforcement learning \n
*Canzhe Zhao*\*, Yanjie Ze\*, Jing Dong, Baoxiang Wang, and Shuai Li, \n
IJCAI, 2023.
- Learning Adversarial Linear Mixture Markov Decision Processes with Bandit Feedback and Unknown Transition \n
*Canzhe Zhao*, Ruofeng Yang, Baoxiang Wang and Shuai Li, \n
ICLR, 2023
- Clustering of Conversational Bandits with Posterior Sampling for User Preference Learning and Elicitation \n
Qizhi Li\*, *Canzhe Zhao*\*, Tong Yu, Junda Wu and Shuai Li, \n
UMUAI, 2023
- Differentially private temporal difference learning with stochastic nonconvex-strongly-concave optimization \n
*Canzhe Zhao*, Yanjie Ze, Jing Dong, Baoxiang Wang, and Shuai Li, \n
WSDM, 2023.
==== 2022
- Knowledge-aware conversational preference elicitation with bandit feedback \n
*Canzhe Zhao*, Tong Yu, Zhihui Xie, and Shuai Li, \n
WWW, 2022.
- Simultaneously learning stochastic and adversarial bandits under the position-based model \n
Cheng Chen, *Canzhe Zhao*, and Shuai Li, \n
AAAI, 2022.
==== 2021
- Clustering of conversational bandits for user preference learning and elicitation \n
Junda Wu\*, *Canzhe Zhao*\*, Tong Yu, Jingyang Li, and Shuai Li, \n
CIKM, 2021.
- Comparison-based conversational recommender system with relative bandit feedback \n
Zhihui Xie, Tong Yu, *Canzhe Zhao*, and Shuai Li, \n
SIGIR, 2021.
=== Preprints
