<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
<title>Publications and Preprints</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Home</div>
<div class="menu-item"><a href="index.html">About&nbsp;me</a></div>
<div class="menu-item"><a href="publications.html" class="current">Publications</a></div>
<div class="menu-item"><a href="experiences.html">Experiences</a></div>
<div class="menu-item"><a href="talks.html">Talks</a></div>
<div class="menu-item"><a href="honors.html">Honors</a></div>
<div class="menu-item"><a href="misc.html">Misc.</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications and Preprints</h1>
<div id="subtitle"><br />
(* indicates equal contribution)</div>
</div>
<h3>Publications</h3>
<h4>2025</h4>
<ul>
<li><p>Learning Imperfect Information Extensive-form Games with Last-iterate Convergence under Bandit Feedback <br />
<b>Canzhe Zhao</b>, Yutian Cheng, Jing Dong, Baoxiang Wang, Shuai Li. <br />
ICML, 2025.</p>
</li>
<li><p>Towards Provably Efficient Learning of Imperfect Information Extensive-Form Games with Linear Function Approximation <br />
<b>Canzhe Zhao</b>, Shuze Chen, Weiming Liu, Haobo Fu, QIANG FU, Shuai Li. <br />
UAI, 2025.</p>
</li>
<li><p>Logarithmic Regret for Linear Markov Decision Processes with Adversarial Corruptions <br />
<b>Canzhe Zhao</b>, XiangCheng Zhang, Baoxiang Wang, and Shuai Li. <br />
AAAI, 2025.</p>
</li>
</ul>
<h4>2023</h4>
<ul>
<li><p>Learning Adversarial Low-rank Markov Decision Processes with Unknown Transition and Full-information Feedback [<a href="https://arxiv.org/abs/2311.07876">arXiv</a>][<a href="./files/23NeurIPS_poster.pdf">poster</a>] <br />
<b>Canzhe Zhao</b>, Ruofeng Yang, Baoxiang Wang, Xuezhou Zhang and Shuai Li. <br />
NeurIPS, 2023.</p>
</li>
<li><p>Best-of-three-worlds analysis for linear bandits with follow-the-regularized-leader algorithm [<a href="https://arxiv.org/abs/2303.06825">arXiv</a>] <br />
Fang Kong, <b>Canzhe Zhao</b>, and Shuai Li. <br />
COLT, 2023.</p>
</li>
<li><p>DPMAC: Differentially private communication for cooperative multi-agent reinforcement learning <br />
<b>Canzhe Zhao</b>*, Yanjie Ze*, Jing Dong, Baoxiang Wang, and Shuai Li. <br />
IJCAI, 2023.</p>
</li>
<li><p>Learning Adversarial Linear Mixture Markov Decision Processes with Bandit Feedback and Unknown Transition [<a href="https://openreview.net/forum?id=sVU54nyaA9K">link</a>][<a href="files\ICLR_2023_pre.pdf">slides</a>] <br />
<b>Canzhe Zhao</b>, Ruofeng Yang, Baoxiang Wang and Shuai Li. <br />
ICLR, 2023</p>
</li>
<li><p>Clustering of Conversational Bandits with Posterior Sampling for User Preference Learning and Elicitation [<a href="https://link.springer.com/article/10.1007/s11257-023-09358-x">link</a>] <br />
Qizhi Li*, <b>Canzhe Zhao</b>*, Tong Yu, Junda Wu and Shuai Li. <br />
UMUAI, 2023</p>
</li>
<li><p>Differentially private temporal difference learning with stochastic nonconvex-strongly-concave optimization [<a href="https://dl.acm.org/doi/10.1145/3539597.3570470">link</a>] <br />
<b>Canzhe Zhao</b>, Yanjie Ze, Jing Dong, Baoxiang Wang, and Shuai Li. <br />
WSDM, 2023.</p>
</li>
</ul>
<h4>2022</h4>
<ul>
<li><p>Knowledge-aware conversational preference elicitation with bandit feedback [<a href="https://dl.acm.org/doi/10.1145/3485447.3512152">link</a>] [<a href="files\WWW_2022_pre.pdf">slides</a>]<br />
<b>Canzhe Zhao</b>, Tong Yu, Zhihui Xie, and Shuai Li. <br />
WWW, 2022.</p>
</li>
<li><p>Simultaneously learning stochastic and adversarial bandits under the position-based model [<a href="https://arxiv.org/abs/2207.05437">arXiv</a>]<br />
Cheng Chen, <b>Canzhe Zhao</b>, and Shuai Li. <br />
AAAI, 2022.</p>
</li>
</ul>
<h4>2021</h4>
<ul>
<li><p>Clustering of conversational bandits for user preference learning and elicitation [<a href="https://dl.acm.org/doi/10.1145/3459637.3482328">link</a>][<a href="files\CIKM_2021_pre.pdf">slides</a>]<br />
Junda Wu*, <b>Canzhe Zhao</b>*, Tong Yu, Jingyang Li, and Shuai Li. <br />
CIKM, 2021.</p>
</li>
<li><p>Comparison-based conversational recommender system with relative bandit feedback [<a href="https://dl.acm.org/doi/10.1145/3404835.3462920">link</a>] <br />
Zhihui Xie, Tong Yu, <b>Canzhe Zhao</b>, and Shuai Li. <br />
SIGIR, 2021.</p>
</li>
</ul>
<h3>Preprints</h3>
<div id="footer">
<div id="footer-text">
Page generated 2025-07-03 00:20:25 +08, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
